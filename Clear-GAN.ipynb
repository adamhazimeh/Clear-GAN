{"cells":[{"cell_type":"markdown","metadata":{"id":"yvVzpkkoli5u"},"source":["The following is an implementation of Clear-GAN as described in the proposal titled: ***Clear-GAN: Cloud Removal in Satellite Imagery via Cyclic Multispectral Generative Adversarial Networks***.\n","\n","In what follows, PyTorch is used for data preprocessing, model construction, training, and evaluation."]},{"cell_type":"markdown","metadata":{"id":"a7i_ft1nhBk2"},"source":["# **Imports and Dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ls1xlVm3eWm7","trusted":true},"outputs":[],"source":["import os\n","\n","import random\n","import itertools\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.backends.cudnn as cudnn\n","import torchvision.transforms as t\n","\n","from torchvision.io import read_image\n","from torch.utils.data import Dataset, random_split\n","import torch.utils.data\n","\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","!pip install jupyterplot\n","from jupyterplot import ProgressPlot"]},{"cell_type":"markdown","metadata":{"id":"-lnnUWDPjJSr"},"source":["# **Dataset**\n","\n","The training dataset is stored in the `dataset.zip` file. When unzipped the `dataset` directory contains two subdirectories: `A`, which corresponds to **cloudy** images, and `B`, which corresponds to **cloudless** images. Each class contains `1735` images for each channel (It is essential that the number of images in both classes are equal in this implementation).\n","\n","```\n","dataset\n","    ├── A\n","        ├── image_1_R.jpg\n","        ├── image_1_G.jpg\n","        ├── image_1_B.jpg\n","        ├── image_1_NIR.jpg\n","        ├── image_2_R.jpg\n","        ├── ...\n","    └── B\n","        ├── image_1_R.jpg\n","        ├── image_1_G.jpg\n","        ├── image_1_B.jpg\n","        ├── image_1_NIR.jpg\n","        ├── image_2_R.jpg\n","        ├── ...\n","```\n","\n","The evaluation dataset (for PSNR calculation) is stored in the `eval.zip` file. When unzipped, the `eval` directory contains paired cloudy and cloudless images (of the same location). Each class contains `608` images for each channel.\n","\n","``` \n","eval\n","    image_1_R_clear.jpg\n","    image_1_R_cloudy.jpg\n","    image_1_G_clear.jpg\n","    image_1_G_cloudy.jpg\n","    image_1_B_clear.jpg\n","    image_1_B_cloudy.jpg\n","    image_2_R_clear.jpg\n","    image_2_R_cloudy.jpg\n","    ...\n","\n","```\n","\n","\n","Each satellite image collected from Sentinel-2 is stored as 4 separate ```.jpg``` files, each consisting of a single channel (R, G, B, NIR).\n","\n","Now, we download the datasets from Google Drive and unzip them."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rd1-Mx-JwyCa","trusted":true},"outputs":[],"source":["!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1qESOHWNCzOpljDj1r34QK5LMiHkE1f0t' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1qESOHWNCzOpljDj1r34QK5LMiHkE1f0t\" -O dataset.zip && rm -rf /tmp/cookies.txt\n","!unzip dataset.zip\n","!rm -rf __MACOSX\n","\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=1hZ6qzpQYxTOG9BVQfSpi4LlnhhFo76Wj' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=1hZ6qzpQYxTOG9BVQfSpi4LlnhhFo76Wj\" -O eval.zip && rm -rf /tmp/cookies.txt\n","!unzip eval.zip\n","!mv ./content/eval ./\n","!rm -rf ./content"]},{"cell_type":"markdown","metadata":{"id":"whsU4tQmh0x0"},"source":["Now, we will define custom datasets compatible with PyTorch. This makes it easier to handle the data for preprocessing, training, and evaluation using a PyTorch `DataLoader` object.\n","\n","The `__getitem__(i)` function returns two 4-channel images (R, G, B, NIR) stored at the given index (ranging from 1 -> 1735), the first being a cloudy image and the second being a cloudless image (unpaired)."]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T21:14:02.206627Z","iopub.status.busy":"2021-12-08T21:14:02.206366Z","iopub.status.idle":"2021-12-08T21:14:02.227867Z","shell.execute_reply":"2021-12-08T21:14:02.227109Z","shell.execute_reply.started":"2021-12-08T21:14:02.206599Z"},"id":"oURhNoGJhmmy","trusted":true},"outputs":[],"source":["class Sentinel2(Dataset):\n","    def __init__(self, dir, transform = None, target_transform = None):\n","        self.dir = dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","        self.channel_map = {1: \"R\",\n","                            2: \"G\",\n","                            3: \"B\",\n","                            4: \"NIR\"}\n","\n","    def __len__(self):\n","        _, _, files = next(os.walk(self.dir + '/A'))\n","        return int(len(files) / 4)\n","\n","    def __getitem__(self, i):\n","        cloudy_image_path = os.path.join(self.dir, 'A', 'image_' + str(i + 1) + '_')\n","        cloudy_shape = read_image(cloudy_image_path + 'R.jpg').shape\n","        cloudy_image = torch.zeros(4, cloudy_shape[1], cloudy_shape[2])\n","\n","        clear_image_path = os.path.join(self.dir, 'B', 'image_' + str(i + 1) + '_')\n","        clear_shape = read_image(clear_image_path + 'R.jpg').shape\n","        clear_image = torch.zeros(4, clear_shape[1], clear_shape[2])\n","\n","        for j in range(1, 5):\n","            cloudy_channel = read_image(cloudy_image_path + self.channel_map[j] + '.jpg')\n","            cloudy_image[j - 1, :, :] = cloudy_channel[0, :, :]\n","\n","            clear_channel = read_image(clear_image_path + self.channel_map[j] + '.jpg')\n","            clear_image[j - 1, :, :] = clear_channel[0, :, :]\n","            \n","        cloudy_image /= 255.0\n","        clear_image /= 255.0\n","\n","        if self.transform:\n","            cloudy_image = self.transform(cloudy_image)\n","            clear_image = self.transform(clear_image)\n","        if self.target_transform:\n","            cloudy_image = self.target_transform(cloudy_image)\n","            clear_image = self.target_transform(clear_image)\n","\n","        return cloudy_image, clear_image\n","    \n","    \n","    \n","class Eval(Dataset):\n","    def __init__(self, dir, transform = None, target_transform = None):\n","        self.dir = dir\n","        self.transform = transform\n","        self.target_transform = target_transform\n","        self.channel_map = {1: \"R\",\n","                            2: \"G\",\n","                            3: \"B\",\n","                            4: \"NIR\"}\n","\n","    def __len__(self):\n","        _, _, files = next(os.walk(self.dir))\n","        return int(len(files) / 8)\n","\n","    def __getitem__(self, i):\n","        cloudy_image_path = os.path.join(self.dir, 'image_' + str(i + 1) + '_')\n","        cloudy_shape = read_image(cloudy_image_path + 'R_cloudy.jpg').shape\n","        cloudy_image = torch.zeros(4, cloudy_shape[1], cloudy_shape[2])\n","\n","        clear_image_path = os.path.join(self.dir, 'image_' + str(i + 1) + '_')\n","        clear_shape = read_image(clear_image_path + 'R_clear.jpg').shape\n","        clear_image = torch.zeros(4, clear_shape[1], clear_shape[2])\n","\n","        for j in range(1, 5):\n","            cloudy_channel = read_image(cloudy_image_path + self.channel_map[j] + '_cloudy.jpg')\n","            cloudy_image[j - 1, :, :] = cloudy_channel[0, :, :]\n","\n","            clear_channel = read_image(clear_image_path + self.channel_map[j] + '_clear.jpg')\n","            clear_image[j - 1, :, :] = clear_channel[0, :, :]\n","            \n","        cloudy_image /= 255.0\n","        clear_image /= 255.0\n","\n","        if self.transform:\n","            cloudy_image = self.transform(cloudy_image)\n","            clear_image = self.transform(clear_image)\n","        if self.target_transform:\n","            cloudy_image = self.target_transform(cloudy_image)\n","            clear_image = self.target_transform(clear_image)\n","\n","        return cloudy_image, clear_image"]},{"cell_type":"markdown","metadata":{"id":"pOjbbgzcGZeP"},"source":["Now, we apply a `Resize` transformation to resize each image into the dimension `(4, 256, 256)`."]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T21:14:03.023723Z","iopub.status.busy":"2021-12-08T21:14:03.023180Z","iopub.status.idle":"2021-12-08T21:14:03.027971Z","shell.execute_reply":"2021-12-08T21:14:03.027322Z","shell.execute_reply.started":"2021-12-08T21:14:03.023680Z"},"id":"1YneHhOgtGw8","trusted":true},"outputs":[],"source":["transform = t.Resize(size = (256, 256))\n","\n","dataset = Sentinel2(dir = 'dataset', transform = transform)\n","eval_dataset = Eval(dir = 'eval', transform = transform)"]},{"cell_type":"markdown","metadata":{"id":"CbKMc0qUHHGZ"},"source":["We visualize a few random samples from the training dataset, displaying (unpaired) cloudy images in the top row and cloudless images in the bottom row (RGB channels only)."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T21:14:13.873118Z","iopub.status.busy":"2021-12-08T21:14:13.872245Z","iopub.status.idle":"2021-12-08T21:14:15.095631Z","shell.execute_reply":"2021-12-08T21:14:15.093927Z","shell.execute_reply.started":"2021-12-08T21:14:13.873081Z"},"id":"c9P8x0sNEwjq","outputId":"d4680f06-ae25-4fd5-e484-d88e6faa51d1","trusted":true},"outputs":[],"source":["n = 4\n","f = plt.figure(figsize = (4 * n, 2 * n))\n","\n","for i in range(n):\n","    img = dataset[np.random.randint(low = 0, high = len(dataset))][0][:3, :, :].permute(1, 2, 0)\n","    f.add_subplot(2, n, i + 1)\n","    plt.axis('off')\n","    plt.imshow(img)\n","\n","for i in range(n):\n","    img = dataset[np.random.randint(low = 0, high = len(dataset))][1][:3, :, :].permute(1, 2, 0)\n","    f.add_subplot(2, n, i + n + 1)\n","    plt.axis('off')\n","    plt.imshow(img)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["We also visualize a few random paired samples from the evaluation dataset in the same order mentioned above."]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T21:14:19.751630Z","iopub.status.busy":"2021-12-08T21:14:19.751014Z","iopub.status.idle":"2021-12-08T21:14:20.757633Z","shell.execute_reply":"2021-12-08T21:14:20.755534Z","shell.execute_reply.started":"2021-12-08T21:14:19.751594Z"},"trusted":true},"outputs":[],"source":["n = 4\n","f = plt.figure(figsize = (4 * n, 2 * n))\n","\n","rand_inds = []\n","\n","for i in range(n):\n","    rand_inds.append(np.random.randint(low = 0, high = len(eval_dataset)))\n","    img = eval_dataset[rand_inds[i]][0][:3, :, :].permute(1, 2, 0)\n","    f.add_subplot(2, n, i + 1)\n","    plt.axis('off')\n","    plt.imshow(img)\n","\n","for i in range(n):\n","    img = eval_dataset[rand_inds[i]][1][:3, :, :].permute(1, 2, 0)\n","    f.add_subplot(2, n, i + n + 1)\n","    plt.axis('off')\n","    plt.imshow(img)\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"xxNZVF5-J35U"},"source":["# **Model Construction**"]},{"cell_type":"markdown","metadata":{"id":"N9IczQZbJ8WQ"},"source":["CycleGAN, as described in the original paper, consists of two discriminators and two generators.\n","\n","<br />\n","\n","**Discriminators**\n","\n","Discriminators in this context are deep convolutional neural nets that perform image classification (real/fake).\n","\n","The first discriminator `(D_A)` classifies images from Domain A (cloudy), while the second `(D_B)` classifies images from Domain B (cloudless).\n","\n","Each discriminator model consists of a set of (1) Convolutional layers, (2) Instance Normalization layers, and (3) Leaky ReLU activation functions."]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T21:14:28.903332Z","iopub.status.busy":"2021-12-08T21:14:28.903036Z","iopub.status.idle":"2021-12-08T21:14:28.914573Z","shell.execute_reply":"2021-12-08T21:14:28.913849Z","shell.execute_reply.started":"2021-12-08T21:14:28.903301Z"},"id":"NfrgDkHS_Ss1","trusted":true},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self):\n","        super(Discriminator, self).__init__()\n","\n","        self.main = nn.Sequential(\n","            nn.Conv2d(4, 64, 4, stride = 2, padding = 1),\n","            nn.LeakyReLU(0.2, inplace = True),\n","\n","            nn.Conv2d(64, 128, 4, stride = 2, padding = 1),\n","            nn.InstanceNorm2d(128),\n","            nn.LeakyReLU(0.2, inplace = True),\n","\n","            nn.Conv2d(128, 256, 4, stride = 2, padding = 1),\n","            nn.InstanceNorm2d(256),\n","            nn.LeakyReLU(0.2, inplace = True),\n","\n","            nn.Conv2d(256, 512, 4, padding = 1),\n","            nn.InstanceNorm2d(512),\n","            nn.LeakyReLU(0.2, inplace = True),\n","\n","            nn.Conv2d(512, 1, 4, padding = 1),\n","            )\n","\n","    def forward(self, x):\n","        x = self.main(x)\n","        x = F.avg_pool2d(x, x.size()[2:])\n","        x = torch.flatten(x, 1)\n","        #x = torch.sigmoid(x)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"UGPJ4o60APSO"},"source":["**Generators**\n","\n","In this context, a generator is an encoder-decoder architecture which downsamples (encodes) the input image, interprets the encoding through a series of `ResNet` blocks, then upsamples (decodes) the result.\n","\n","Each `ResNet` block consists of two `Conv2d` layers with `3x3` filters.\n","\n","The first generator `(G_A2B)` maps an image from Domain A (cloudy) to Domain B (cloudless), while the second generator `(G_B2A)` maps an image from Domain B (cloudless) to Domain A (cloudy)."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T21:14:29.424347Z","iopub.status.busy":"2021-12-08T21:14:29.423954Z","iopub.status.idle":"2021-12-08T21:14:29.438441Z","shell.execute_reply":"2021-12-08T21:14:29.437710Z","shell.execute_reply.started":"2021-12-08T21:14:29.424314Z"},"id":"d1nicxDZBF08","trusted":true},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self):\n","        super(Generator, self).__init__()\n","        self.main = nn.Sequential(\n","            #Initial Convolution\n","            nn.ReflectionPad2d(3),\n","            nn.Conv2d(4, 64, 7),\n","            nn.InstanceNorm2d(64),\n","            nn.ReLU(inplace = True),\n","\n","            #Encoder\n","            nn.Conv2d(64, 128, 3, stride = 2, padding = 1),\n","            nn.InstanceNorm2d(128),\n","            nn.ReLU(inplace = True),\n","            nn.Conv2d(128, 256, 3, stride = 2, padding = 1),\n","            nn.InstanceNorm2d(256),\n","            nn.ReLU(inplace = True),\n","\n","            #Residual Block Sequence\n","            ResidualBlock(256),\n","            ResidualBlock(256),\n","            ResidualBlock(256),\n","            ResidualBlock(256),\n","            ResidualBlock(256),\n","            ResidualBlock(256),\n","            ResidualBlock(256),\n","            ResidualBlock(256),\n","            ResidualBlock(256),\n","\n","            #Decoder\n","            nn.ConvTranspose2d(256, 128, 3, stride = 2, padding = 1, output_padding = 1),\n","            nn.InstanceNorm2d(128),\n","            nn.ReLU(inplace = True),\n","            nn.ConvTranspose2d(128, 64, 3, stride = 2, padding = 1, output_padding = 1),\n","            nn.InstanceNorm2d(64),\n","            nn.ReLU(inplace = True),\n","\n","            #Output\n","            nn.ReflectionPad2d(3),\n","            nn.Conv2d(64, 4, 7),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, x):\n","        return self.main(x)\n","\n","\n","class ResidualBlock(nn.Module):\n","    def __init__(self, in_channels):\n","        super(ResidualBlock, self).__init__()\n","\n","        self.res = nn.Sequential(nn.ReflectionPad2d(1),\n","                                 nn.Conv2d(in_channels, in_channels, 3),\n","                                 nn.InstanceNorm2d(in_channels),\n","                                 nn.ReLU(inplace = True),\n","                                 nn.ReflectionPad2d(1),\n","                                 nn.Conv2d(in_channels, in_channels, 3),\n","                                 nn.InstanceNorm2d(in_channels))\n","\n","    def forward(self, x):\n","        return x + self.res(x)"]},{"cell_type":"markdown","metadata":{"id":"9PdntZYvDiqa"},"source":["# **Model Training**\n","\n","First, we define the class `DecayLR` for learning rate decay. This will be used during weight optimization."]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T21:14:29.986736Z","iopub.status.busy":"2021-12-08T21:14:29.984419Z","iopub.status.idle":"2021-12-08T21:14:29.994930Z","shell.execute_reply":"2021-12-08T21:14:29.994083Z","shell.execute_reply.started":"2021-12-08T21:14:29.986682Z"},"id":"0TC3EnwbDZSp","trusted":true},"outputs":[],"source":["class DecayLR:\n","    def __init__(self, epochs, offset, decay_epochs):\n","        epoch_flag = epochs - decay_epochs\n","        assert (epoch_flag > 0), \"Decay must start before the training session ends!\"\n","        self.epochs = epochs\n","        self.offset = offset\n","        self.decay_epochs = decay_epochs\n","\n","    def step(self, epoch):\n","        return 1.0 - max(0, epoch + self.offset - self.decay_epochs) / (\n","                self.epochs - self.decay_epochs)"]},{"cell_type":"markdown","metadata":{"id":"0oRwsBF1FP0-"},"source":["We also define a few helper functions."]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T21:16:57.104360Z","iopub.status.busy":"2021-12-08T21:16:57.103685Z","iopub.status.idle":"2021-12-08T21:16:57.114655Z","shell.execute_reply":"2021-12-08T21:16:57.113897Z","shell.execute_reply.started":"2021-12-08T21:16:57.104326Z"},"id":"EbqSXqnZFVtt","trusted":true},"outputs":[],"source":["#Weight Initialization\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    \n","    if classname.find(\"Conv\") != -1:\n","        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n","\n","    elif classname.find(\"BatchNorm\") != -1:\n","        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n","        torch.nn.init.zeros_(m.bias)\n","        \n","#Buffer for efficiency in backpropagation\n","class ReplayBuffer:\n","    def __init__(self, max_size=50):\n","        assert (max_size > 0), \"Empty buffer or trying to create a black hole. Be careful.\"\n","        self.max_size = max_size\n","        self.data = []\n","\n","    def push_and_pop(self, data):\n","        to_return = []\n","        for element in data.data:\n","            element = torch.unsqueeze(element, 0)\n","            if len(self.data) < self.max_size:\n","                self.data.append(element)\n","                to_return.append(element)\n","            else:\n","                if random.uniform(0, 1) > 0.5:\n","                    i = random.randint(0, self.max_size - 1)\n","                    to_return.append(self.data[i].clone())\n","                    self.data[i] = element\n","                else:\n","                    to_return.append(element)\n","        return torch.cat(to_return)\n","\n","#Peak Signal-to-Noise Ratio (used for evaluation of the generator models)\n","def PSNR(real_image, gen_image):\n","    mse = torch.mean((real_image - gen_image) ** 2)\n","    return 20 * torch.log10(1.0 / torch.sqrt(mse))"]},{"cell_type":"markdown","metadata":{"id":"pOcdh5J_D-rG"},"source":["Now, we train the four models `D_A, D_B, G_A2B, and G_B2A`."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T17:59:50.130427Z","iopub.status.busy":"2021-12-08T17:59:50.130152Z","iopub.status.idle":"2021-12-08T19:57:05.101168Z","shell.execute_reply":"2021-12-08T19:57:05.100503Z","shell.execute_reply.started":"2021-12-08T17:59:50.130395Z"},"trusted":true},"outputs":[],"source":["def train(trainset, hp, first_time = True, num_saved_epochs = 0):\n","    #Create a 'weights' folder for checkpointing\n","    if first_time:\n","        try:\n","            os.makedirs(\"weights\")\n","        except OSError:\n","            pass\n","\n","    #DataLoader Instantiation\n","    dataloader = torch.utils.data.DataLoader(trainset, batch_size=hp['batch_size'], shuffle=True, pin_memory=True)\n","\n","    #Switch to GPU if available\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","    #Model Instantiation\n","    G_A2B = Generator().to(device)\n","    G_B2A = Generator().to(device)\n","    D_A = Discriminator().to(device)\n","    D_B = Discriminator().to(device)\n","\n","    #Weight Initialization\n","    if first_time:\n","        G_A2B.apply(weights_init)\n","        G_B2A.apply(weights_init)\n","        D_A.apply(weights_init)\n","        D_B.apply(weights_init)\n","    else:\n","        G_A2B.load_state_dict(torch.load(f\"weights/G_A2B_epoch_{num_saved_epochs - 1}.pth\"))\n","        G_B2A.load_state_dict(torch.load(f\"weights/G_B2A_epoch_{num_saved_epochs - 1}.pth\"))\n","        D_A.load_state_dict(torch.load(f\"weights/D_A_epoch_{num_saved_epochs - 1}.pth\"))\n","        D_B.load_state_dict(torch.load(f\"weights/D_B_epoch_{num_saved_epochs - 1}.pth\"))\n","\n","    #Loss Functions\n","    cyc_loss = torch.nn.L1Loss().to(device)\n","    idt_loss = torch.nn.L1Loss().to(device)\n","    adv_loss = torch.nn.MSELoss().to(device)\n","\n","    #Optimizers\n","    optimizer_G = torch.optim.Adam(itertools.chain(G_A2B.parameters(), G_B2A.parameters()),\n","                                   lr=hp['lr'],\n","                                   betas=(0.5, 0.999))\n","    optimizer_D_A = torch.optim.Adam(D_A.parameters(), lr=hp['lr'], betas=(0.5, 0.999))\n","    optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=hp['lr'], betas=(0.5, 0.999))\n","\n","    #Learning Rate Schedulers\n","    lr_lambda = DecayLR(hp['epochs'], 0, hp['decay_epochs']).step\n","    lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lr_lambda)\n","    lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lr_lambda)\n","    lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lr_lambda)\n","\n","    g_losses, d_losses, idt_losses, gan_losses, cyc_losses = [], [], [], [], []\n","\n","    fake_A_buffer = ReplayBuffer()\n","    fake_B_buffer = ReplayBuffer()\n","\n","    #liveloss = PlotLosses()\n","    curr_iter = 0 if first_time else num_saved_epochs * len(dataloader)\n","    pp = ProgressPlot(line_names = [\"Loss_D\", \"Loss_G\"],\n","                      x_iterator=False,\n","                      x_label=\"Epochs\")\n","    \n","    for epoch in range(hp['epochs']):\n","        progress_bar = tqdm(enumerate(dataloader), total = len(dataloader))\n","        for i, data in progress_bar:\n","            plot_log = {}\n","\n","            #Load data batch\n","            real_A = data[0].to(device)\n","            real_B = data[1].to(device)\n","            batch_size = real_A.size(0)\n","\n","            real_label = torch.full((batch_size, 1), 1, device=device, dtype=torch.float32)\n","            fake_label = torch.full((batch_size, 1), 0, device=device, dtype=torch.float32)\n","\n","            #########################################\n","            #Update G network: Generators A2B and B2A\n","            #########################################\n","            optimizer_G.zero_grad()\n","\n","            #Identity loss (G_B2A(A) should equal A if real A is fed)\n","            idt_A = G_B2A(real_A)\n","            loss_idt_A = idt_loss(idt_A, real_A) * 5.0\n","\n","            #Identity Loss (G_A2B(B) should equal B if real B is fed)\n","            idt_B = G_A2B(real_B)\n","            loss_idt_B = idt_loss(idt_B, real_B) * 5.0\n","\n","\n","            #GAN loss D_A(G_A(A))\n","            fake_A = G_B2A(real_B)\n","            fake_output_A = D_A(fake_A)\n","            loss_GAN_B2A = adv_loss(fake_output_A, real_label)\n","\n","            #GAN loss D_B(G_B(B))\n","            fake_B = G_A2B(real_A)\n","            fake_output_B = D_B(fake_B)\n","            loss_GAN_A2B = adv_loss(fake_output_B, real_label)\n","\n","\n","            #Cycle loss\n","            recovered_image_A = G_B2A(fake_B)\n","            loss_cycle_ABA = cyc_loss(recovered_image_A, real_A) * 10.0\n","\n","            recovered_image_B = G_A2B(fake_A)\n","            loss_cycle_BAB = cyc_loss(recovered_image_B, real_B) * 10.0\n","\n","            #Combine losses\n","            errG = loss_idt_A + loss_idt_B + loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB\n","\n","            #Calculate gradients for G_A and G_B\n","            errG.backward()\n","\n","            #Update G_A and G_B's weights\n","            optimizer_G.step()\n","\n","            ##############################################\n","            # (2) Update D network: Discriminator A\n","            ##############################################\n","            optimizer_D_A.zero_grad()\n","\n","            #Real A image loss\n","            real_output_A = D_A(real_A)\n","            errD_real_A = adv_loss(real_output_A, real_label)\n","\n","            #Fake A image loss\n","            fake_A = fake_A_buffer.push_and_pop(fake_A)\n","            fake_output_A = D_A(fake_A.detach())\n","            errD_fake_A = adv_loss(fake_output_A, fake_label)\n","\n","            #Combine losses\n","            errD_A = (errD_real_A + errD_fake_A) / 2\n","\n","            #Calculate gradients for D_A\n","            errD_A.backward()\n","\n","            #Update D_A weights\n","            optimizer_D_A.step()\n","\n","            ##############################################\n","            # (3) Update D network: Discriminator B\n","            ##############################################\n","            optimizer_D_B.zero_grad()\n","\n","            #Real B image loss\n","            real_output_B = D_B(real_B)\n","            errD_real_B = adv_loss(real_output_B, real_label)\n","\n","            #Fake B image loss\n","            fake_B = fake_B_buffer.push_and_pop(fake_B)\n","            fake_output_B = D_B(fake_B.detach())\n","            errD_fake_B = adv_loss(fake_output_B, fake_label)\n","\n","            #Combined losses\n","            errD_B = (errD_real_B + errD_fake_B) / 2\n","\n","            #Calculate gradients for D_B\n","            errD_B.backward()\n","\n","            #Update D_B weights\n","            optimizer_D_B.step()\n","\n","            #Display progress and losses\n","            progress_bar.set_description(\n","                f\"[{epoch + num_saved_epochs + 1}/{hp['epochs'] + num_saved_epochs}][{i}/{len(dataloader) - 1}] \"\n","                f\"Loss_D: {(errD_A + errD_B).item():.4f} \"\n","                f\"Loss_G: {errG.item():.4f} \"\n","                f\"Loss_G_identity: {(loss_idt_A + loss_idt_B).item():.4f} \"\n","                f\"Loss_G_GAN: {(loss_GAN_A2B + loss_GAN_B2A).item():.4f} \"\n","                f\"Loss_G_cycle: {(loss_cycle_ABA + loss_cycle_BAB).item():.4f}\")\n","            \n","            if curr_iter % 2 == 0:   \n","                pp.update(curr_iter / len(dataloader), [[(errD_A + errD_B).item(), errG.item()]])\n","                \n","            curr_iter += 1\n","\n","        #Update learning rates\n","        lr_scheduler_G.step()\n","        lr_scheduler_D_A.step()\n","        lr_scheduler_D_B.step()\n","\n","        #Create model weight checkpoints\n","        ep = epoch + num_saved_epochs if not first_time else epoch\n","        torch.save(G_A2B.state_dict(), f\"weights/G_A2B_epoch_{ep}.pth\")\n","        torch.save(G_B2A.state_dict(), f\"weights/G_B2A_epoch_{ep}.pth\")\n","        torch.save(D_A.state_dict(), f\"weights/D_A_epoch_{ep}.pth\")\n","        torch.save(D_B.state_dict(), f\"weights/D_B_epoch_{ep}.pth\")\n","    \n","    pp.finalize()\n","    \n","    return G_A2B, G_B2A, D_A, D_B\n","\n","#Define hyperparameters\n","hp = {'batch_size': 4,\n","      'lr': 2e-4,\n","      'epochs': 20,\n","      'decay_epochs': 10}\n","\n","#Train the models\n","G_A2B, G_B2A, D_A, D_B = train(trainset = dataset, hp = hp, first_time = False, num_saved_epochs = 50)"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T21:46:38.964211Z","iopub.status.busy":"2021-12-08T21:46:38.963965Z","iopub.status.idle":"2021-12-08T21:47:10.216910Z","shell.execute_reply":"2021-12-08T21:47:10.216240Z","shell.execute_reply.started":"2021-12-08T21:46:38.964183Z"},"trusted":true},"outputs":[],"source":["def load_models(num_saved_epochs):\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    \n","    G_A2B = Generator().to(device)\n","    G_B2A = Generator().to(device)\n","    D_A = Discriminator().to(device)\n","    D_B = Discriminator().to(device)\n","\n","    G_A2B.load_state_dict(torch.load(f\"weights/G_A2B_epoch_{num_saved_epochs - 1}.pth\"))\n","    G_B2A.load_state_dict(torch.load(f\"weights/G_B2A_epoch_{num_saved_epochs - 1}.pth\"))\n","    D_A.load_state_dict(torch.load(f\"weights/D_A_epoch_{num_saved_epochs - 1}.pth\"))\n","    D_B.load_state_dict(torch.load(f\"weights/D_B_epoch_{num_saved_epochs - 1}.pth\"))\n","    \n","    return G_A2B, G_B2A, D_A, D_B\n","\n","def evaluate(G_A2B, G_B2A, eval_dataset):\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    G_A2B.train(False)\n","    G_B2A.train(False)\n","    \n","    dataloader = torch.utils.data.DataLoader(eval_dataset, batch_size = 1, shuffle = False)\n","    total_removal_PSNR = 0\n","    total_addition_PSNR = 0\n","    for i, data in enumerate(dataloader):\n","        real_cloudy, real_clear = data\n","        real_cloudy = real_cloudy.to(device)\n","        real_clear = real_clear.to(device)\n","        \n","        with torch.no_grad():\n","            gen_clear = G_A2B(real_cloudy)\n","            gen_cloudy = G_B2A(real_clear)\n","            \n","        removal_PSNR = PSNR(real_clear, gen_clear)\n","        addition_PSNR = PSNR(real_cloudy, gen_cloudy)\n","        \n","        total_removal_PSNR += removal_PSNR\n","        total_addition_PSNR += addition_PSNR\n","    \n","    return (total_removal_PSNR / len(dataloader)).item(), (total_addition_PSNR / len(dataloader)).item()\n","\n","\n","G_A2B, G_B2A, D_A, D_B = load_models(70)\n","av_removal_PSNR, av_addition_PSNR = evaluate(G_A2B, G_B2A, eval_dataset)\n","\n","print(f'Average PSNR for Cloud Removal: {av_removal_PSNR} dB')\n","print(f'Average PSNR for Cloud Addition: {av_addition_PSNR} dB')"]},{"cell_type":"markdown","metadata":{},"source":["Now, we visualize generated cloud removal exmaples using images from the evaluation dataset. In the top row, we display the real cloudy images, followed by their paired real cloudless images on the second row, and finally generated cloudless images on the third row."]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2021-12-08T21:46:00.992247Z","iopub.status.busy":"2021-12-08T21:46:00.991970Z","iopub.status.idle":"2021-12-08T21:46:02.137623Z","shell.execute_reply":"2021-12-08T21:46:02.136795Z","shell.execute_reply.started":"2021-12-08T21:46:00.992217Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","n = 3\n","f = plt.figure(figsize = (4 * n, 4 * n))\n","\n","rand_inds = []\n","\n","for i in range(n):\n","    rand_inds.append(np.random.randint(low = 0, high = len(eval_dataset)))\n","    img = eval_dataset[rand_inds[i]][0][:3, :, :].permute(1, 2, 0)\n","    f.add_subplot(3, n, i + 1)\n","    plt.axis('off')\n","    plt.imshow(img)\n","\n","for i in range(n):\n","    img = eval_dataset[rand_inds[i]][1][:3, :, :].permute(1, 2, 0)\n","    f.add_subplot(3, n, i + n + 1)\n","    plt.axis('off')\n","    plt.imshow(img)\n","\n","for i in range(n):\n","    img = eval_dataset[rand_inds[i]][0]\n","    gen_img = G_A2B(img.unsqueeze(0).to(device)).squeeze()[:3, :, :].permute(1, 2, 0).cpu().detach().numpy()\n","    f.add_subplot(3, n, i + 2*n + 1)\n","    plt.axis('off')\n","    plt.imshow(gen_img)\n","\n","\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Credits\n","\n","This project's CycleGAN implementation relied heavily on that contributed by GitHub user Lornatang (https://github.com/Lornatang/CycleGAN-PyTorch)."]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
